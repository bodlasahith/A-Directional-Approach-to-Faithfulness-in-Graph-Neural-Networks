{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.models.gnn_models import create_model\n",
    "from src.faithfulness.ablation import NodeAblator, DirectionalAblator\n",
    "from src.utils.metrics import evaluate_faithfulness\n",
    "from src.utils.tracking import init_experiment, log_metrics, log_graph_example, finish_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8496873",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e36081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'dataset': 'MUTAG',\n",
    "    'model': 'gcn',\n",
    "    'hidden_channels': 64,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.5,\n",
    "    'epochs': 200,\n",
    "    'lr': 0.01,\n",
    "    'batch_size': 32,\n",
    "    'seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "print(f\"Device: {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9944732",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a04d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MUTAG dataset\n",
    "dataset = TUDataset(root='../data/raw', name=CONFIG['dataset'])\n",
    "\n",
    "print(f\"Dataset: {CONFIG['dataset']}\")\n",
    "print(f\"  Graphs: {len(dataset)}\")\n",
    "print(f\"  Features: {dataset.num_features}\")\n",
    "print(f\"  Classes: {dataset.num_classes}\")\n",
    "print(f\"\\nExample graph:\")\n",
    "print(f\"  Nodes: {dataset[0].num_nodes}\")\n",
    "print(f\"  Edges: {dataset[0].edge_index.size(1)}\")\n",
    "print(f\"  Label: {dataset[0].y.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f04400",
   "metadata": {},
   "source": [
    "## 3. Train GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6722cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "dataset = dataset.shuffle()\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "val_dataset = dataset[train_size:train_size + val_size]\n",
    "test_dataset = dataset[train_size + val_size:]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'])\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc042229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_model(\n",
    "    CONFIG['model'],\n",
    "    in_channels=dataset.num_features,\n",
    "    hidden_channels=CONFIG['hidden_channels'],\n",
    "    out_channels=dataset.num_classes,\n",
    "    num_layers=CONFIG['num_layers'],\n",
    "    dropout=CONFIG['dropout']\n",
    ").to(CONFIG['device'])\n",
    "\n",
    "print(f\"Model: {CONFIG['model'].upper()}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        correct += (out.argmax(dim=1) == data.y).sum().item()\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.cross_entropy(out, data.y)\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        correct += (out.argmax(dim=1) == data.y).sum().item()\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['lr'])\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, CONFIG['device'])\n",
    "    val_loss, val_acc = evaluate(model, val_loader, CONFIG['device'])\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:3d}: train_loss={train_loss:.4f}, train_acc={train_acc:.4f}, \"\n",
    "              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "# Test accuracy\n",
    "test_loss, test_acc = evaluate(model, test_loader, CONFIG['device'])\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acee620e",
   "metadata": {},
   "source": [
    "## 4. Generate Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create explainer\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Get explanation for a test graph\n",
    "test_data = test_dataset[0].to(CONFIG['device'])\n",
    "explanation = explainer(test_data.x, test_data.edge_index, target=test_data.y)\n",
    "\n",
    "print(\"Explanation generated:\")\n",
    "print(f\"  Node importance shape: {explanation.node_mask.shape}\")\n",
    "print(f\"  Edge importance shape: {explanation.edge_mask.shape}\")\n",
    "print(f\"  Top-5 important nodes: {torch.topk(explanation.node_mask, k=5).indices.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f3e1f",
   "metadata": {},
   "source": [
    "## 5. Faithfulness Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e44b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ablators\n",
    "node_ablator = NodeAblator(ablation_mode=\"zero\")\n",
    "dir_ablator = DirectionalAblator(node_ablator)\n",
    "\n",
    "# Run necessity test\n",
    "print(\"Running necessity test...\")\n",
    "original_probs = []\n",
    "ablated_probs = []\n",
    "\n",
    "for i, data in enumerate(test_dataset[:20]):\n",
    "    data = data.to(CONFIG['device'])\n",
    "    \n",
    "    # Get original prediction\n",
    "    out = model(data.x, data.edge_index, data.batch)\n",
    "    pred = out.argmax(dim=1).item()\n",
    "    prob_orig = F.softmax(out, dim=1)[0, pred].item()\n",
    "    original_probs.append(prob_orig)\n",
    "    \n",
    "    # Get explanation\n",
    "    explanation = explainer(data.x, data.edge_index, target=torch.tensor([pred]))\n",
    "    \n",
    "    # Ablate top-3 nodes\n",
    "    top_nodes = torch.topk(explanation.node_mask, k=min(3, len(explanation.node_mask))).indices.tolist()\n",
    "    data_ablated = node_ablator.ablate(data, top_nodes)\n",
    "    \n",
    "    # Get ablated prediction\n",
    "    out_ablated = model(data_ablated.x, data_ablated.edge_index, data_ablated.batch)\n",
    "    prob_ablated = F.softmax(out_ablated, dim=1)[0, pred].item()\n",
    "    ablated_probs.append(prob_ablated)\n",
    "\n",
    "# Compute necessity scores\n",
    "necessity_scores = [(o - a) / o for o, a in zip(original_probs, ablated_probs) if o > 0]\n",
    "print(f\"\\nNecessity score: {np.mean(necessity_scores):.4f} Â± {np.std(necessity_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Training curves\n",
    "axes[0].plot(train_accs, label='Train')\n",
    "axes[0].plot(val_accs, label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Training Progress')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Faithfulness\n",
    "axes[1].scatter(original_probs, ablated_probs, alpha=0.6)\n",
    "axes[1].plot([0, 1], [0, 1], 'r--', alpha=0.5, label='y=x')\n",
    "axes[1].set_xlabel('Original Probability')\n",
    "axes[1].set_ylabel('Ablated Probability')\n",
    "axes[1].set_title('Necessity Test (should drop below y=x)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/baseline_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8bcc4f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Training a GNN model on graph classification\n",
    "- Generating explanations with GNNExplainer  \n",
    "- Testing faithfulness with necessity tests\n",
    "- Measuring confidence drops after ablating important nodes\n",
    "\n",
    "Next steps:\n",
    "- Implement sufficiency tests\n",
    "- Add directionality analysis for edges\n",
    "- Compare across multiple explainer methods\n",
    "- Test on more complex datasets"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
